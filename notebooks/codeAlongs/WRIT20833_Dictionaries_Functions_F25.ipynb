{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6k5W2OvIZL5c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k5W2OvIZL5c",
        "outputId": "d5fcbd60-bfc3-484c-da9e-42c7fecb8a31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35f094fb",
      "metadata": {
        "id": "35f094fb"
      },
      "source": [
        "# Structuring Knowledge, Automating Analysis\n",
        "## Dictionaries and Functions in Digital Humanities (DH)\n",
        "\n",
        "Welcome to our exploration of how we organize complex information and automate repetitive tasks in digital humanities (DH) scholarship. Today we'll learn about two powerful Python tools that transform how we work with cultural data: **dictionaries** for organizing rich, structured information, and **functions** for automating our analytical processes.\n",
        "\n",
        "In DH, we constantly work with *complex cultural objects* that have multiple attributes: a manuscript has an author, date, location, language, and genre; a historical figure has a name, birth year, occupation, and social networks; an artwork has a creator, medium, dimensions, and cultural context. **Dictionaries** help us keep all this interconnected information organized and accessible.\n",
        "\n",
        "But our work often involves *repetitive analytical tasks*: calculating word frequencies across hundreds of texts, standardizing inconsistent historical data, or generating reports across multiple collections. **Functions** allow us to write analytical procedures once and apply them systematically across our materials.\n",
        "\n",
        "Today's title reflects a fundamental shift in DH: from \"structuring knowledge\" (organizing what we know about *cultural objects* via **dictionaries**) to \"automating analysis\" (*systematically applying* our scholarly methods at scale, via **functions**).\n",
        "  \n",
        "### Understanding Data Complexity: From Simple to Structured\n",
        "\n",
        "Let's connect today's concepts to what we've already learned:\n",
        "\n",
        "- **Variables** = **Individual facts**: A single piece of information (a title, a date, a name)\n",
        "- **Lists** = **Collections of *similar* items**: Multiple related pieces of the same type (all the book titles in a library, all the dates in a timeline)\n",
        "- **Dictionaries** = *Complex cultural objects*: Multiple different types of information about a single item (all the metadata about one book, all the details about one historical event)\n",
        "- **Functions** = *Analytical procedures*: Reusable methods for processing cultural data systematically\n",
        "\n",
        "Think of today's lesson as learning to create detailed library catalog entries for *complex cultural materials*, then developing *systematic methods for analyzing* those collections at scale."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49c20a6c",
      "metadata": {
        "id": "49c20a6c"
      },
      "source": [
        "## Part 1: What Are Dictionaries?\n",
        "\n",
        "A dictionary is like a detailed catalog card (for books) or database record. While a **list** stores multiple items of the same type in order, a **dictionary** stores *multiple pieces of different information* about a single subject. It's the difference between a simple bibliography (a **list** of titles only) and a comprehensive catalog entry (a **dictionary** of titles, authors, dates, publishers, subjects, etc.).\n",
        "\n",
        "In DH, **dictionaries** let us represent the rich, multifaceted nature of *cultural objects and historical subjects*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d590d4d8",
      "metadata": {
        "id": "d590d4d8"
      },
      "outputs": [],
      "source": [
        "# A simple list - just titles\n",
        "book_titles = [\"Beloved\", \"Invisible Man\", \"Their Eyes Were Watching God\"]\n",
        "\n",
        "# A dictionary - rich information about one book\n",
        "book_record = {\n",
        "    \"title\": \"Beloved\",\n",
        "    \"author\": \"Toni Morrison\",\n",
        "    \"publication_year\": 1987,\n",
        "    \"genre\": \"Historical Fiction\",\n",
        "    \"setting\": \"Ohio, post-Civil War\",\n",
        "    \"awards\": [\"Pulitzer Prize\", \"Nobel Prize contributor\"],\n",
        "    \"themes\": [\"memory\", \"trauma\", \"motherhood\", \"slavery\"]\n",
        "}\n",
        "\n",
        "print(\"Simple list:\", book_titles)\n",
        "print(\"\\nRich dictionary:\")\n",
        "for key, value in book_record.items():\n",
        "    print(f\"{key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3194ed92",
      "metadata": {
        "id": "3194ed92"
      },
      "source": [
        "### Try it yourself:\n",
        "Create a dictionary representing a digital media object you're familiar with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75422fa2",
      "metadata": {
        "id": "75422fa2"
      },
      "outputs": [],
      "source": [
        "# Your turn: create a dictionary for a podcast, video game, social media creator, etc.\n",
        "my_media_object = {\n",
        "    # Add key-value pairs here\n",
        "    # \"title\": \"...\",\n",
        "    # \"creator\": \"...\",\n",
        "    # \"year\": ...,\n",
        "    # Add more attributes that matter for your chosen object\n",
        "}\n",
        "\n",
        "print(my_media_object)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3fc3bb7",
      "metadata": {
        "id": "c3fc3bb7"
      },
      "source": [
        "## Part 2: Accessing and Understanding Dictionary Structure\n",
        "\n",
        "Just as scholars need to extract specific information from catalog records, we need systematic ways to access information stored in dictionaries. Unlike lists (which have numerical positions for indexing), dictionaries use meaningful **keys** (data categories) to access **values** (the data in those categories)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2f45875",
      "metadata": {
        "id": "f2f45875"
      },
      "outputs": [],
      "source": [
        "# Historical figure from digital humanities research\n",
        "historical_figure = {\n",
        "    \"name\": \"Ida B. Wells-Barnett\",\n",
        "    \"birth_year\": 1862,\n",
        "    \"death_year\": 1931,\n",
        "    \"occupation\": [\"journalist\", \"activist\", \"researcher\"],\n",
        "    \"known_for\": \"anti-lynching research and activism\",\n",
        "    \"publications\": [\"Southern Horrors\", \"The Red Record\"],\n",
        "    \"methodology\": \"data-driven journalism\"\n",
        "}\n",
        "\n",
        "# Accessing specific information\n",
        "print(f\"Name: {historical_figure['name']}\")\n",
        "print(f\"Birth year: {historical_figure['birth_year']}\")\n",
        "print(f\"Known for: {historical_figure['known_for']}\")\n",
        "\n",
        "# What if we want all the keys (categories of information)?\n",
        "print(f\"\\nAvailable information: {list(historical_figure.keys())}\")\n",
        "\n",
        "# What if we want all the values (the actual data)?\n",
        "print(f\"\\nAll data: {list(historical_figure.values())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9396b750",
      "metadata": {
        "id": "9396b750"
      },
      "source": [
        "### Discussion Question:\n",
        "Compare Ida B. Wells-Barnett's \"methodology\" (see **key** in code above) with modern digital humanities approaches. How do both use data systematically to understand social patterns?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e6850ab",
      "metadata": {
        "id": "6e6850ab"
      },
      "outputs": [],
      "source": [
        "# Try accessing different pieces of information from your dictionary above\n",
        "# What happens if you try to access a key that doesn't exist?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78b1fe2e",
      "metadata": {
        "id": "78b1fe2e"
      },
      "source": [
        "## Part 2.5: Modifying and Building Dictionaries - Evolving Knowledge\n",
        "\n",
        "Scholarly knowledge evolves as we discover new information, correct errors, or add new analytical categories. Dictionaries in Python are **mutable** (changeable, as in \"mutation\"), meaning we can update their values as our understanding of cultural objects deepens.\n",
        "\n",
        "This flexibility mirrors how digital archives and scholarly databases grow and change over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a52c03a6",
      "metadata": {
        "id": "a52c03a6"
      },
      "outputs": [],
      "source": [
        "# Let's build a record for a contemporary digital creator\n",
        "creator_profile = {\n",
        "    \"name\": \"Contrapoints (Natalie Wynn)\",\n",
        "    \"platform\": \"YouTube\",\n",
        "    \"content_type\": \"video essays\",\n",
        "    \"debut_year\": 2016\n",
        "}\n",
        "\n",
        "print(\"Initial profile:\", creator_profile)\n",
        "\n",
        "# Adding new information as we research further\n",
        "creator_profile[\"subscriber_count\"] = \"1.6M+ (as of 2025)\"\n",
        "creator_profile[\"topics\"] = [\"philosophy\", \"politics\", \"gender theory\", \"internet culture\"]\n",
        "creator_profile[\"production_style\"] = [\"theatrical\", \"academic\", \"satirical\"]\n",
        "\n",
        "# Updating existing information\n",
        "creator_profile[\"platform\"] = [\"YouTube\", \"Patreon\"]  # More comprehensive\n",
        "\n",
        "# Checking our expanded record\n",
        "print(\"\\nExpanded profile:\")\n",
        "for category, info in creator_profile.items():\n",
        "    print(f\"  {category}: {info}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc605e1e",
      "metadata": {
        "id": "fc605e1e"
      },
      "source": [
        "## Part 3: Working with Complex Cultural Collections\n",
        "\n",
        "Substantial DH projects often involve multiple related objects--like all the works by an author, all the artifacts from a time period, or all the documents from an archive. We can organize these using **dictionaries within dictionaries**, creating rich, interconnected datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a61446d7",
      "metadata": {
        "id": "a61446d7"
      },
      "outputs": [],
      "source": [
        "# A small digital archive of Harlem Renaissance writers\n",
        "harlem_renaissance = {\n",
        "    \"langston_hughes\": {\n",
        "        \"full_name\": \"James Mercer Langston Hughes\",\n",
        "        \"birth_year\": 1901,\n",
        "        \"death_year\": 1967,\n",
        "        \"genres\": [\"poetry\", \"novels\", \"short stories\", \"plays\"],\n",
        "        \"famous_works\": [\"The Weary Blues\", \"Montage of a Dream Deferred\"],\n",
        "        \"themes\": [\"jazz culture\", \"racial pride\", \"American dream\"],\n",
        "        \"innovation\": \"jazz poetry\"\n",
        "    },\n",
        "    \"zora_neale_hurston\": {\n",
        "        \"full_name\": \"Zora Neale Hurston\",\n",
        "        \"birth_year\": 1891,\n",
        "        \"death_year\": 1960,\n",
        "        \"genres\": [\"novels\", \"short stories\", \"anthropology\", \"folklore\"],\n",
        "        \"famous_works\": [\"Their Eyes Were Watching God\", \"Mules and Men\"],\n",
        "        \"themes\": [\"Black womanhood\", \"Southern culture\", \"folk traditions\"],\n",
        "        \"innovation\": \"anthropological fiction\"\n",
        "    },\n",
        "    \"claude_mckay\": {\n",
        "        \"full_name\": \"Festus Claudius McKay\",\n",
        "        \"birth_year\": 1889,\n",
        "        \"death_year\": 1948,\n",
        "        \"genres\": [\"poetry\", \"novels\"],\n",
        "        \"famous_works\": [\"Harlem Shadows\", \"Home to Harlem\"],\n",
        "        \"themes\": [\"racial protest\", \"exile\", \"urban life\"],\n",
        "        \"innovation\": \"sonnet form for racial themes\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Analyzing our collection\n",
        "print(\"Harlem Renaissance Digital Archive\")\n",
        "print(\"=\" * 35)\n",
        "\n",
        "for writer_key, writer_info in harlem_renaissance.items():\n",
        "    name = writer_info[\"full_name\"]\n",
        "    innovation = writer_info[\"innovation\"]\n",
        "    print(f\"{name}: {innovation}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b10e58e",
      "metadata": {
        "id": "9b10e58e"
      },
      "source": [
        "### Try It Yourself: Building a Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "924d07e2",
      "metadata": {
        "id": "924d07e2"
      },
      "outputs": [],
      "source": [
        "# Create a small collection of related cultural objects\n",
        "# Examples: favorite podcasts, influential video games, important films, etc.\n",
        "my_collection = {\n",
        "    # \"object1_key\": {\n",
        "    #     \"title\": \"...\",\n",
        "    #     \"creator\": \"...\",\n",
        "    #     \"year\": ...,\n",
        "    #     \"significance\": \"...\"\n",
        "    # },\n",
        "    # Add more objects...\n",
        "}\n",
        "\n",
        "# Analyze your collection\n",
        "print(\"My Cultural Collection:\")\n",
        "print(\"=\" * 25)\n",
        "# Add code to display information about your collection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7631702d",
      "metadata": {
        "id": "7631702d"
      },
      "source": [
        "## Part 4: Systematic Analysis with Loops and Dictionaries\n",
        "\n",
        "One of the most powerful aspects of working with structured cultural data is the ability to ask *systematic questions* across entire collections. We can combine **loops** with **dictionaries** to analyze patterns, extract insights, and generate reports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "956803a5",
      "metadata": {
        "id": "956803a5"
      },
      "outputs": [],
      "source": [
        "# Let's analyze patterns in our Harlem Renaissance collection\n",
        "\n",
        "print(\"=== Birth Year Analysis ===\")\n",
        "birth_years = []\n",
        "for writer in harlem_renaissance.values():\n",
        "    birth_years.append(writer[\"birth_year\"])\n",
        "    print(f\"{writer['full_name']}: born {writer['birth_year']}\")\n",
        "\n",
        "earliest = min(birth_years)\n",
        "latest = max(birth_years)\n",
        "print(f\"\\nGeneration span: {earliest} to {latest} ({latest - earliest} years)\")\n",
        "\n",
        "print(\"\\n=== Innovation Analysis ===\")\n",
        "for writer_key, writer_data in harlem_renaissance.items():\n",
        "    name = writer_data[\"full_name\"]\n",
        "    innovation = writer_data[\"innovation\"]\n",
        "    themes = \", \".join(writer_data[\"themes\"][:2])  # First two themes\n",
        "    print(f\"{name}: {innovation}\")\n",
        "    print(f\"  Key themes: {themes}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05088e87",
      "metadata": {
        "id": "05088e87"
      },
      "source": [
        "## Part 5: Introduction to Functions - Automating Scholarly Methods\n",
        "\n",
        "As digital humanists, we often find ourselves *repeating the same analytical procedures* across different texts, datasets, or collections. **Functions** allow us to encapsulate our scholarly methods into reusable tools, making our work more efficient and reproducible.\n",
        "\n",
        "Think of **functions** as automated scholarly procedures--like having a research assistant who can apply the same analytical method to any material you give them.\n",
        "\n",
        "### From Collection Analysis to Individual Object Analysis\n",
        "\n",
        "So far, we've worked with our **entire collection** (`harlem_renaissance`) using loops. Now we'll learn to create functions that work with **individual cultural objects** (like a single writer's dictionary).\n",
        "\n",
        "For example, instead of analyzing all writers at once, we can create a function that analyzes just one writer, then apply that function to any writer we choose. This gives us more flexibility and reusable analytical tools."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9addada",
      "metadata": {
        "id": "a9addada"
      },
      "source": [
        "### Basic Function Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4e5b3d5",
      "metadata": {
        "id": "b4e5b3d5"
      },
      "outputs": [],
      "source": [
        "# A very simple function to start with\n",
        "def get_writer_innovation(writer_dict):\n",
        "    \"\"\"\n",
        "    Extract a writer's key innovation from their dictionary.\n",
        "    This is a simple function that takes input and returns output.\n",
        "    \"\"\"\n",
        "    innovation = writer_dict[\"innovation\"]\n",
        "    return innovation\n",
        "\n",
        "# Using our simple function\n",
        "print(\"=== Simple Function Example ===\")\n",
        "langston_innovation = get_writer_innovation(harlem_renaissance[\"langston_hughes\"])\n",
        "print(f\"Langston Hughes' innovation: {langston_innovation}\")\n",
        "\n",
        "zora_innovation = get_writer_innovation(harlem_renaissance[\"zora_neale_hurston\"])\n",
        "print(f\"Zora Neale Hurston's innovation: {zora_innovation}\")\n",
        "\n",
        "# Notice:\n",
        "# 1. The function takes one input (a writer dictionary)\n",
        "# 2. It does something with that input (extracts the innovation)\n",
        "# 3. It returns a result that we can use"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9ff856a",
      "metadata": {
        "id": "a9ff856a"
      },
      "source": [
        "### Building Complexity: From Simple Extraction to Analysis\n",
        "\n",
        "Now let's build on this basic pattern with a more sophisticated function that performs analysis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b98af458",
      "metadata": {
        "id": "b98af458"
      },
      "outputs": [],
      "source": [
        "# A simple function for scholarly analysis\n",
        "def analyze_writer_lifespan(writer_dict):\n",
        "    \"\"\"\n",
        "    Calculate and describe a writer's lifespan from biographical data.\n",
        "    This function takes a writer dictionary and returns analytical information.\n",
        "\n",
        "    Parameter:\n",
        "        writer_dict: A single writer's dictionary (like harlem_renaissance[\"langston_hughes\"])\n",
        "    \"\"\"\n",
        "    name = writer_dict[\"full_name\"]\n",
        "    birth = writer_dict[\"birth_year\"]\n",
        "    death = writer_dict[\"death_year\"]\n",
        "\n",
        "    lifespan = death - birth\n",
        "\n",
        "    print(f\"{name} ({birth}-{death})\")\n",
        "    print(f\"Lived {lifespan} years\")\n",
        "\n",
        "    if lifespan < 50:\n",
        "        print(\"Brief but impactful life\")\n",
        "    elif lifespan < 70:\n",
        "        print(\"Full creative career\")\n",
        "    else:\n",
        "        print(\"Long, influential life\")\n",
        "\n",
        "    return lifespan\n",
        "\n",
        "# Using our function with individual writer dictionaries from our collection\n",
        "print(\"=== Writer Lifespan Analysis ===\")\n",
        "# Note: harlem_renaissance[\"langston_hughes\"] gives us just one writer's dictionary\n",
        "langston_lifespan = analyze_writer_lifespan(harlem_renaissance[\"langston_hughes\"])\n",
        "print(f\"Returned value: {langston_lifespan} years\\n\")\n",
        "\n",
        "zora_lifespan = analyze_writer_lifespan(harlem_renaissance[\"zora_neale_hurston\"])\n",
        "print(f\"Returned value: {zora_lifespan} years\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51bf60f1",
      "metadata": {
        "id": "51bf60f1"
      },
      "source": [
        "### Functions with Multiple Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "293384ed",
      "metadata": {
        "id": "293384ed"
      },
      "outputs": [],
      "source": [
        "def compare_writers(writer1_dict, writer2_dict, comparison_attribute):\n",
        "    \"\"\"\n",
        "    Compare two writers based on a specified attribute.\n",
        "    This demonstrates how functions can take multiple inputs for complex analysis.\n",
        "    \"\"\"\n",
        "    name1 = writer1_dict[\"full_name\"]\n",
        "    name2 = writer2_dict[\"full_name\"]\n",
        "\n",
        "    value1 = writer1_dict[comparison_attribute]\n",
        "    value2 = writer2_dict[comparison_attribute]\n",
        "\n",
        "    print(f\"Comparing {name1} and {name2}:\")\n",
        "    print(f\"  {name1}'s {comparison_attribute}: {value1}\")\n",
        "    print(f\"  {name2}'s {comparison_attribute}: {value2}\")\n",
        "\n",
        "    if comparison_attribute == \"birth_year\":\n",
        "        if value1 < value2:\n",
        "            print(f\"  {name1} was born earlier\")\n",
        "        elif value1 > value2:\n",
        "            print(f\"  {name2} was born earlier\")\n",
        "        else:\n",
        "            print(\"  They were born in the same year\")\n",
        "\n",
        "    return (value1, value2)\n",
        "\n",
        "# Using our comparison function\n",
        "print(\"=== Writer Comparison Analysis ===\")\n",
        "birth_comparison = compare_writers(\n",
        "    harlem_renaissance[\"langston_hughes\"],\n",
        "    harlem_renaissance[\"claude_mckay\"],\n",
        "    \"birth_year\"\n",
        ")\n",
        "print(f\"Birth years: {birth_comparison}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c84165b",
      "metadata": {
        "id": "8c84165b"
      },
      "source": [
        "## Part 6: Advanced Functions for Cultural Data Analysis\n",
        "\n",
        "Substantial DH work often requires sophisticated **functions** that can process complex cultural datasets, handle edge cases, and provide meaningful insights. Let's build functions that demonstrate professional DH analytical techniques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a718a63",
      "metadata": {
        "id": "3a718a63"
      },
      "outputs": [],
      "source": [
        "def extract_themes_from_collection(collection_dict):\n",
        "    \"\"\"\n",
        "    Extract and count all themes across a cultural collection.\n",
        "    This function demonstrates how to analyze patterns across datasets.\n",
        "    \"\"\"\n",
        "    all_themes = []\n",
        "\n",
        "    # Collect all themes from all writers\n",
        "    for writer_key, writer_data in collection_dict.items():\n",
        "        themes = writer_data.get(\"themes\", [])  # Safe access with default\n",
        "        all_themes.extend(themes)\n",
        "\n",
        "    # Count theme frequency\n",
        "    theme_counts = {}\n",
        "    for theme in all_themes:\n",
        "        if theme in theme_counts:\n",
        "            theme_counts[theme] += 1\n",
        "        else:\n",
        "            theme_counts[theme] = 1\n",
        "\n",
        "    return theme_counts\n",
        "\n",
        "def generate_collection_report(collection_dict, collection_name):\n",
        "    \"\"\"\n",
        "    Generate a comprehensive report about a cultural collection.\n",
        "    This demonstrates how functions can create professional outputs.\n",
        "    \"\"\"\n",
        "    print(f\"=== {collection_name} Analysis Report ===\")\n",
        "    print(f\"Collection size: {len(collection_dict)} individuals\")\n",
        "\n",
        "    # Birth year analysis\n",
        "    birth_years = [writer[\"birth_year\"] for writer in collection_dict.values()]\n",
        "    earliest_birth = min(birth_years)\n",
        "    latest_birth = max(birth_years)\n",
        "\n",
        "    print(f\"Birth year range: {earliest_birth} to {latest_birth}\")\n",
        "    print(f\"Generation span: {latest_birth - earliest_birth} years\")\n",
        "\n",
        "    # Theme analysis\n",
        "    themes = extract_themes_from_collection(collection_dict)\n",
        "    print(f\"\\nThematic diversity: {len(themes)} unique themes\")\n",
        "\n",
        "    # Most common themes\n",
        "    sorted_themes = sorted(themes.items(), key=lambda x: x[1], reverse=True)\n",
        "    print(\"Most common themes:\")\n",
        "    for theme, count in sorted_themes[:3]:\n",
        "        print(f\"  - {theme}: appears {count} time(s)\")\n",
        "\n",
        "    return {\n",
        "        \"size\": len(collection_dict),\n",
        "        \"birth_range\": (earliest_birth, latest_birth),\n",
        "        \"themes\": themes\n",
        "    }\n",
        "\n",
        "# Using our advanced functions\n",
        "report_data = generate_collection_report(harlem_renaissance, \"Harlem Renaissance Writers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb94ec19",
      "metadata": {
        "id": "bb94ec19"
      },
      "source": [
        "### ðŸŽ¯ You Try: Building Your Own Analysis Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40fe64f8",
      "metadata": {
        "id": "40fe64f8"
      },
      "outputs": [],
      "source": [
        "def analyze_my_collection(collection_dict):\n",
        "    \"\"\"\n",
        "    Create your own function to analyze your cultural collection.\n",
        "    Think about what questions you want to ask of your data.\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    # Examples of what you might analyze:\n",
        "    # - Most common creators or years\n",
        "    # - Average length of titles\n",
        "    # - Distribution across categories\n",
        "    # - Patterns in your data\n",
        "\n",
        "\n",
        "# Test your function with your collection\n",
        "# analyze_my_collection(my_collection)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3625e28",
      "metadata": {
        "id": "a3625e28"
      },
      "source": [
        "## ðŸŽµ Fun Interlude: The Banana Fanna Function Challenge\n",
        "\n",
        "Before we dive into real-world applications, let's have some fun with functions! This exercise combines string manipulation, function creation, and iteration--all key skills in DH text processing.\n",
        "\n",
        "### Aims of the Exercise\n",
        "\n",
        "Create functions that manipulate names in specified creative ways, as illustrated in \"[The Name Game](https://www.youtube.com/watch?v=NeF7jqf0GU4.)\" song (1964). This might seem silly, but the underlying skills (string manipulation, pattern recognition, systematic processing) are fundamental to text analysis in DH.\n",
        "\n",
        "### The Three Practice Challenges\n",
        "\n",
        "1. **String Transformation / Data Normalization**: Write a function that transforms text (like normalizing historical name variants)\n",
        "2. **Pattern Recognition & Generation**: Create a function that follows a specific pattern (like generating consistent citation formats)  \n",
        "3. **Systematic / Iterative Processing**: Apply your function systematically across a dataset (like standardizing an entire collection)\n",
        "\n",
        "These are exactly the kinds of operations we do in DH--just with more playful content!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c830f763",
      "metadata": {
        "id": "c830f763",
        "vscode": {
          "languageId": "code"
        }
      },
      "outputs": [],
      "source": [
        "# The dataset we'll work with\n",
        "names = [\"becky\", \"timmy\", \"kyle\", \"sam\", \"kendra\", \"marcela\", \"curt\"]\n",
        "\n",
        "print(\"Our dataset:\", names)\n",
        "print(\"Ready to transform this data systematically!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0c3a9b8",
      "metadata": {
        "id": "f0c3a9b8"
      },
      "source": [
        "### ðŸŽ¯ Practice 1: String Transformation / Data Normalization Function\n",
        "\n",
        "**Challenge**: Write a function that *changes* the list so that all the names are in all caps. The function cannot just print the names--it must change the original list.\n",
        "\n",
        "*Why this matters* in DH: Normalizing data formats is crucial for analysis. Historical records often have inconsistent capitalization, spelling variants, or formatting. Learning to systematically transform data prepares you for more substantial text cleaning tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa23b4cb",
      "metadata": {
        "id": "fa23b4cb",
        "vscode": {
          "languageId": "code"
        }
      },
      "outputs": [],
      "source": [
        "def make_names_uppercase(name_list):\n",
        "    \"\"\"\n",
        "    Transform all names in a list to uppercase.\n",
        "    This modifies the original list (in-place transformation).\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    # Hint: You'll need to loop through the list and modify each item\n",
        "    # Remember: string.upper() makes a string uppercase\n",
        "\n",
        "\n",
        "# Test your function\n",
        "print(\"Before:\", names)\n",
        "make_names_uppercase(names)\n",
        "print(\"After:\", names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fa8a0b2",
      "metadata": {
        "id": "7fa8a0b2"
      },
      "source": [
        "### ðŸŽ¯ Practice 2: Pattern Recognition & Generation Function\n",
        "\n",
        "**Challenge**: Write a function that puts someone's name into the \"banana fana fo fana\" song.\n",
        "\n",
        "Using the name Katie as an example, the song follows this pattern:\n",
        "```\n",
        "Katie, Katie, bo-batie,\n",
        "Bonana-fanna fo-fatie\n",
        "Fee fi mo-matie\n",
        "Katie!\n",
        "```\n",
        "\n",
        "Run your function on one of the names from the names list above.\n",
        "\n",
        "*Why this matters* in DH: Pattern recognition and generation are fundamental to text analysis. Whether you're generating bibliographic citations, creating consistent metadata formats, or normalizing historical documents, you're applying systematic patterns to transform text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09c5367f",
      "metadata": {
        "id": "09c5367f",
        "vscode": {
          "languageId": "code"
        }
      },
      "outputs": [],
      "source": [
        "def banana_fanna_song(name):\n",
        "\n",
        "    # Generate the \"banana fanna fo fanna\" lyrics for a given name.\n",
        "    # This demonstrates pattern-based text generation.\n",
        "\n",
        "    # Your code here\n",
        "    # Hint: You'll need to:\n",
        "    # 1. Work with the name to create the rhyming parts\n",
        "    # 2. Follow the specific pattern shown above\n",
        "    # 3. Handle both uppercase and lowercase names\n",
        "\n",
        "    # The pattern is:\n",
        "    # [Name], [Name], bo-b[name without first letter],\n",
        "    # Bonana-fanna fo-f[name without first letter]\n",
        "    # Fee fi mo-m[name without first letter]\n",
        "    # [Name]!\n",
        "\n",
        "\n",
        "\n",
        "# Test your function\n",
        "test_name = \"Katie\"\n",
        "print(f\"Testing with {test_name}:\")\n",
        "banana_fanna_song(test_name)\n",
        "\n",
        "print(f\"\\nTesting with one of our names:\")\n",
        "banana_fanna_song(names[0])  # Test with the first name from our list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40c4aad0",
      "metadata": {
        "id": "40c4aad0"
      },
      "source": [
        "### ðŸŽ¯ Practice 3: Systematic / Iterative Processing\n",
        "\n",
        "**Challenge**: Write a for **loop** that applies the banana fanna **function** to the now all-caps name list. Or, write a function that does Practice 2 iteratively on a list. Two ways to get to the same thing.\n",
        "\n",
        "**Discussion Question**: What's the difference between these two approaches?\n",
        "\n",
        "*Why this matters* in DH: This is the essence of computational text analysis--taking a procedure you can do by hand and systematically applying it across an entire corpus. Whether you're analyzing sentiment across thousands of tweets, extracting named entities from historical documents, or generating metadata for a digital collection, you're using this same pattern: *function + iteration = systematic analysis*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f3ea93a",
      "metadata": {
        "id": "0f3ea93a",
        "vscode": {
          "languageId": "code"
        }
      },
      "outputs": [],
      "source": [
        "# Approach 1: Using a for loop with our existing function\n",
        "print(\"=== Approach 1: Loop + Function ===\")\n",
        "for name in names:\n",
        "    print(f\"\\nSong for {name}:\")\n",
        "    banana_fanna_song(name)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Approach 2: Create a function that processes the entire list\n",
        "def banana_fanna_for_all(name_list):\n",
        "\n",
        "    # Process an entire list of names with the banana fanna song.\n",
        "    # This demonstrates how to create functions that work on collections.\n",
        "\n",
        "    print(\"=== Approach 2: Collection Processing Function ===\")\n",
        "\n",
        "    # Your code here\n",
        "    # This function should call banana_fanna_song() for each name in the list\n",
        "\n",
        "\n",
        "# Test the collection processing function\n",
        "banana_fanna_for_all(names)\n",
        "\n",
        "# Discussion: What are the advantages of each approach?\n",
        "# When might you use one vs the other in digital humanities work?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53b34dae",
      "metadata": {
        "id": "53b34dae"
      },
      "source": [
        "### ðŸ¤” Reflection: From Silly Songs to Serious Scholarship\n",
        "\n",
        "What you just practiced with the \"Name Game\" exercise are foundational skills for computational text analysis:\n",
        "\n",
        "1. **Data Normalization / String Transformation** (Practice 1): Making data consistent for analysis\n",
        "   - *In DH*: Standardizing historical spelling variants, normalizing metadata formats\n",
        "   \n",
        "2. **Pattern Recognition & Generation** (Practice 2): Following systematic rules to transform text\n",
        "   - *In DH*: Creating consistent citations, extracting structured data from unstructured text\n",
        "   \n",
        "3. **Systematic / Iterative Processing** (Practice 3): Applying procedures systematically across datasets\n",
        "   - *In DH*: Analyzing thousands of documents, processing entire digital collections\n",
        "\n",
        "The skills are the same whether you're generating silly songs or serious scholarship. The difference is the nature of the data, the complexity of the patterns, and the significance of the insights you generate.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2ab279f",
      "metadata": {
        "id": "d2ab279f"
      },
      "source": [
        "## Part 7: Real-World Digital Humanities Applications\n",
        "\n",
        "Let's explore how dictionaries and functions work together in actual DH research scenarios. These examples demonstrate the kind of systematic cultural analysis that drives contemporary scholarship."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c243a1f",
      "metadata": {
        "id": "2c243a1f"
      },
      "outputs": [],
      "source": [
        "# Simulating a digital humanities research project:\n",
        "# Analyzing representation in contemporary streaming content\n",
        "\n",
        "streaming_content = {\n",
        "    \"bridgerton\": {\n",
        "        \"title\": \"Bridgerton\",\n",
        "        \"platform\": \"Netflix\",\n",
        "        \"year\": 2020,\n",
        "        \"genre\": \"period drama\",\n",
        "        \"lead_demographics\": [\"multiracial casting\", \"female-centered\"],\n",
        "        \"cultural_significance\": \"reimagining historical representation\",\n",
        "        \"viewer_millions\": 82\n",
        "    },\n",
        "    \"squid_game\": {\n",
        "        \"title\": \"Squid Game\",\n",
        "        \"platform\": \"Netflix\",\n",
        "        \"year\": 2021,\n",
        "        \"genre\": \"thriller\",\n",
        "        \"lead_demographics\": [\"Korean cast\", \"working-class focus\"],\n",
        "        \"cultural_significance\": \"global non-English breakthrough\",\n",
        "        \"viewer_millions\": 111\n",
        "    },\n",
        "    \"reservation_dogs\": {\n",
        "        \"title\": \"Reservation Dogs\",\n",
        "        \"platform\": \"Hulu\",\n",
        "        \"year\": 2021,\n",
        "        \"genre\": \"comedy-drama\",\n",
        "        \"lead_demographics\": [\"Indigenous youth\", \"rural community\"],\n",
        "        \"cultural_significance\": \"authentic Indigenous storytelling\",\n",
        "        \"viewer_millions\": 2.8\n",
        "    }\n",
        "}\n",
        "\n",
        "def analyze_representation_patterns(content_collection):\n",
        "    \"\"\"\n",
        "    Analyze patterns of representation in streaming content.\n",
        "    This function demonstrates how DH scholars study media representation.\n",
        "    \"\"\"\n",
        "    print(\"=== Representation Analysis ===\")\n",
        "\n",
        "    platforms = {}\n",
        "    total_viewers = 0\n",
        "    years = []\n",
        "\n",
        "    for show_key, show_data in content_collection.items():\n",
        "        # Platform analysis\n",
        "        platform = show_data[\"platform\"]\n",
        "        if platform in platforms:\n",
        "            platforms[platform] += 1\n",
        "        else:\n",
        "            platforms[platform] = 1\n",
        "\n",
        "        # Viewership analysis\n",
        "        viewers = show_data[\"viewer_millions\"]\n",
        "        total_viewers += viewers\n",
        "\n",
        "        # Temporal analysis\n",
        "        years.append(show_data[\"year\"])\n",
        "\n",
        "        # Cultural significance reporting\n",
        "        title = show_data[\"title\"]\n",
        "        demographics = \", \".join(show_data[\"lead_demographics\"])\n",
        "        significance = show_data[\"cultural_significance\"]\n",
        "\n",
        "        print(f\"{title} ({show_data['year']}):\")\n",
        "        print(f\"  Demographics: {demographics}\")\n",
        "        print(f\"  Significance: {significance}\")\n",
        "        print(f\"  Viewership: {viewers}M\")\n",
        "        print()\n",
        "\n",
        "    # Summary statistics\n",
        "    print(\"=== Summary Statistics ===\")\n",
        "    print(f\"Total shows analyzed: {len(content_collection)}\")\n",
        "    print(f\"Platform distribution: {platforms}\")\n",
        "    print(f\"Year range: {min(years)}-{max(years)}\")\n",
        "    print(f\"Average viewership: {total_viewers/len(content_collection):.1f}M\")\n",
        "\n",
        "    return {\n",
        "        \"platforms\": platforms,\n",
        "        \"avg_viewership\": total_viewers/len(content_collection),\n",
        "        \"year_range\": (min(years), max(years))\n",
        "    }\n",
        "\n",
        "# Run our analysis\n",
        "analysis_results = analyze_representation_patterns(streaming_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f839d2bc",
      "metadata": {
        "id": "f839d2bc"
      },
      "source": [
        "## Part 8: Data Cleaning and Standardization Functions\n",
        "\n",
        "Cultural data is often messy, inconsistent, or incomplete. Digital humanists need robust functions that can clean, standardize, and prepare data for analysis. This is crucial work that underlies all subsequent scholarly analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7ab7ae2",
      "metadata": {
        "id": "a7ab7ae2"
      },
      "outputs": [],
      "source": [
        "# Messy historical data (typical of what we encounter in archives)\n",
        "messy_historical_data = {\n",
        "    \"person1\": {\n",
        "        \"name\": \"Mary Gallagher (?)\",\n",
        "        \"age\": \"28 years\",\n",
        "        \"occupation\": \"married woman\",\n",
        "        \"location\": \"County Cork, Ireland\"\n",
        "    },\n",
        "    \"person2\": {\n",
        "        \"name\": \"JOHN SANIN\",\n",
        "        \"age\": \"19\",\n",
        "        \"occupation\": \"laborer\",\n",
        "        \"location\": \"cork county, ireland\"\n",
        "    },\n",
        "    \"person3\": {\n",
        "        \"name\": \"Anthony Clark Jr.\",\n",
        "        \"age\": \"unknown\",\n",
        "        \"occupation\": \"Laborer\",\n",
        "        \"location\": \"Cork County\"\n",
        "    }\n",
        "}\n",
        "\n",
        "def standardize_historical_record(person_dict):\n",
        "    \"\"\"\n",
        "    Clean and standardize messy historical data.\n",
        "    This function demonstrates essential data preparation work in DH.\n",
        "    \"\"\"\n",
        "    cleaned_record = {}\n",
        "\n",
        "    # Standardize name (remove uncertainty markers, fix capitalization)\n",
        "    name = person_dict[\"name\"]\n",
        "    name = name.replace(\" (?)\", \"\").replace(\"(?)\", \"\")  # Remove uncertainty\n",
        "    name = name.title()  # Proper capitalization\n",
        "    cleaned_record[\"name\"] = name\n",
        "\n",
        "    # Standardize age (extract numbers, handle missing data)\n",
        "    age_raw = person_dict[\"age\"]\n",
        "    if \"unknown\" in age_raw.lower():\n",
        "        cleaned_record[\"age\"] = None\n",
        "        cleaned_record[\"age_estimated\"] = False\n",
        "    else:\n",
        "        # Extract just the number\n",
        "        age_clean = ''.join(filter(str.isdigit, age_raw))\n",
        "        cleaned_record[\"age\"] = int(age_clean) if age_clean else None\n",
        "        cleaned_record[\"age_estimated\"] = \"?\" in person_dict[\"name\"]\n",
        "\n",
        "    # Standardize occupation (consistent categories)\n",
        "    occupation = person_dict[\"occupation\"].lower()\n",
        "    if \"married\" in occupation:\n",
        "        cleaned_record[\"occupation\"] = \"married\"\n",
        "        cleaned_record[\"gender\"] = \"female\"\n",
        "    elif \"laborer\" in occupation:\n",
        "        cleaned_record[\"occupation\"] = \"laborer\"\n",
        "        cleaned_record[\"gender\"] = \"male\"  # Historical assumption, could be refined\n",
        "    else:\n",
        "        cleaned_record[\"occupation\"] = occupation\n",
        "        cleaned_record[\"gender\"] = \"unknown\"\n",
        "\n",
        "    # Standardize location\n",
        "    location = person_dict[\"location\"]\n",
        "    location = location.title().replace(\",\", \", \")  # Consistent formatting\n",
        "    cleaned_record[\"location\"] = location\n",
        "\n",
        "    return cleaned_record\n",
        "\n",
        "def process_historical_collection(messy_collection):\n",
        "    \"\"\"\n",
        "    Apply standardization to an entire historical collection.\n",
        "    This demonstrates batch processing of cultural data.\n",
        "    \"\"\"\n",
        "    cleaned_collection = {}\n",
        "\n",
        "    print(\"=== Data Cleaning Process ===\")\n",
        "\n",
        "    for person_id, person_data in messy_collection.items():\n",
        "        print(f\"Processing {person_id}:\")\n",
        "        print(f\"  Original: {person_data['name']}\")\n",
        "\n",
        "        cleaned_data = standardize_historical_record(person_data)\n",
        "        cleaned_collection[person_id] = cleaned_data\n",
        "\n",
        "        print(f\"  Cleaned: {cleaned_data['name']}\")\n",
        "        print(f\"  Age: {cleaned_data['age']} (estimated: {cleaned_data['age_estimated']})\")\n",
        "        print(f\"  Occupation: {cleaned_data['occupation']}\")\n",
        "        print()\n",
        "\n",
        "    return cleaned_collection\n",
        "\n",
        "# Process our messy data\n",
        "cleaned_data = process_historical_collection(messy_historical_data)\n",
        "\n",
        "# Verify our cleaning worked\n",
        "print(\"=== Cleaned Dataset Summary ===\")\n",
        "for person_id, clean_data in cleaned_data.items():\n",
        "    print(f\"{clean_data['name']}: {clean_data['occupation']}, age {clean_data['age']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "478e2937",
      "metadata": {
        "id": "478e2937"
      },
      "source": [
        "## Part 9: Your Turn - A Digital Humanities Research Project\n",
        "\n",
        "Now it's time to apply what you've learned. Choose one of the three research project options below or create your own. Each project combines dictionaries for data organization with functions for systematic analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9092710d",
      "metadata": {
        "id": "9092710d"
      },
      "source": [
        "### Option 1: Contemporary Music Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeef58e9",
      "metadata": {
        "id": "eeef58e9"
      },
      "outputs": [],
      "source": [
        "# Create a collection of contemporary musicians/artists with rich metadata\n",
        "music_collection = {\n",
        "    # Example structure:\n",
        "    # \"artist_key\": {\n",
        "    #     \"name\": \"Artist Name\",\n",
        "    #     \"genre\": \"primary genre\",\n",
        "    #     \"debut_year\": 20XX,\n",
        "    #     \"origin\": \"City, Country\",\n",
        "    #     \"themes\": [\"theme1\", \"theme2\"],\n",
        "    #     \"cultural_impact\": \"description\",\n",
        "    #     \"streaming_millions\": XXX\n",
        "    # }\n",
        "}\n",
        "\n",
        "def analyze_music_trends(collection):\n",
        "    \"\"\"\n",
        "    Write a function to analyze patterns in contemporary music.\n",
        "    Consider: geographic distribution, genre evolution, themes, etc.\n",
        "    \"\"\"\n",
        "    # Your analysis code here\n",
        "\n",
        "\n",
        "# Your tasks:\n",
        "# 1. Add at least 4 artists with complete metadata\n",
        "# 2. Implement the analysis function\n",
        "# 3. Run analysis and interpret results\n",
        "# 4. Consider what this tells us about contemporary culture\n",
        "\n",
        "# Write your code here:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d639f805",
      "metadata": {
        "id": "d639f805"
      },
      "source": [
        "### Option 2: Social Media Creator Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37ba5a1e",
      "metadata": {
        "id": "37ba5a1e"
      },
      "outputs": [],
      "source": [
        "# Create a collection of social media creators across platforms\n",
        "creator_collection = {\n",
        "    # Example structure:\n",
        "    # \"creator_key\": {\n",
        "    #     \"name\": \"Creator Name\",\n",
        "    #     \"platform\": \"primary platform\",\n",
        "    #     \"content_type\": \"videos/posts/etc\",\n",
        "    #     \"follower_count\": \"1.5M\",\n",
        "    #     \"demographic\": [\"young adult\", \"LGBTQ+\", etc.],\n",
        "    #     \"topics\": [\"topic1\", \"topic2\"],\n",
        "    #     \"cultural_role\": \"description\"\n",
        "    # }\n",
        "}\n",
        "\n",
        "def analyze_creator_ecosystem(collection):\n",
        "    \"\"\"\n",
        "    Write a function to analyze the social media creator landscape.\n",
        "    Consider: platform distribution, demographics, content types, etc.\n",
        "    \"\"\"\n",
        "    # Your analysis code here\n",
        "\n",
        "# Your tasks:\n",
        "# 1. Add creators from different platforms and demographics\n",
        "# 2. Implement comprehensive analysis\n",
        "# 3. Consider what this reveals about digital culture\n",
        "# 4. Think about representation and access\n",
        "\n",
        "# Write your code here:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba9a9cc2",
      "metadata": {
        "id": "ba9a9cc2"
      },
      "source": [
        "### Option 3: Video Game Cultural Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4eed081d",
      "metadata": {
        "id": "4eed081d"
      },
      "outputs": [],
      "source": [
        "# Create a collection of influential video games\n",
        "game_collection = {\n",
        "    # Example structure:\n",
        "    # \"game_key\": {\n",
        "    #     \"title\": \"Game Title\",\n",
        "    #     \"release_year\": 20XX,\n",
        "    #     \"developer\": \"Studio Name\",\n",
        "    #     \"genre\": \"primary genre\",\n",
        "    #     \"cultural_themes\": [\"theme1\", \"theme2\"],\n",
        "    #     \"representation\": [\"demographic1\", \"demographic2\"],\n",
        "    #     \"innovation\": \"what it introduced\",\n",
        "    #     \"sales_millions\": XX\n",
        "    # }\n",
        "}\n",
        "\n",
        "def analyze_gaming_culture(collection):\n",
        "    \"\"\"\n",
        "    Write a function to analyze trends in video game culture.\n",
        "    Consider: representation, themes, innovation, temporal patterns, etc.\n",
        "    \"\"\"\n",
        "    # Your analysis code here\n",
        "\n",
        "\n",
        "# Your tasks:\n",
        "# 1. Add games that represent different eras and approaches\n",
        "# 2. Analyze cultural and technological trends\n",
        "# 3. Consider questions of representation and access\n",
        "# 4. Think about games as cultural texts\n",
        "\n",
        "# Write your code here:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21fb7579",
      "metadata": {
        "id": "21fb7579"
      },
      "source": [
        "## Reflection Questions\n",
        "\n",
        "As we conclude our exploration of dictionaries and functions, consider these questions about data, knowledge, and analysis:\n",
        "\n",
        "1. **Structured Knowledge**: How does organizing information in dictionaries change the kinds of questions we can ask about culture? What details become visible or invisible in this process?\n",
        "\n",
        "2. **Analytical Automation**: What are the benefits and risks of automating scholarly analysis through functions? What aspects of interpretation should remain human?\n",
        "\n",
        "3. **Data Representation**: When we structure cultural objects as dictionaries, what aspects of those objects might we be overlooking? How do our categories shape our conclusions?\n",
        "\n",
        "4. **Scale and Intimacy**: How does the ability to analyze hundreds or thousands of cultural objects automatically change our relationship to individual works? What do we gain and lose?\n",
        "\n",
        "5. **Future Applications**: How might the skills you've learned today apply to your own research interests? What cultural collections would you want to organize and analyze?\n",
        "\n",
        "Write your thoughts in the Text cell below:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd94e0b0",
      "metadata": {
        "id": "bd94e0b0"
      },
      "source": [
        "### Your Reflections:\n",
        "\n",
        "(Double-click this cell to edit and write your thoughts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "825f0e6e",
      "metadata": {
        "id": "825f0e6e"
      },
      "source": [
        "## Key Takeaways\n",
        "\n",
        "Today we've learned powerful tools for organizing and analyzing cultural data:\n",
        "\n",
        "**Dictionaries for Cultural Data**\n",
        "- **Structure complex information** about cultural objects, people, and phenomena\n",
        "- **Organize rich metadata** that preserves the multifaceted nature of cultural materials\n",
        "- **Enable sophisticated queries** about relationships and patterns in collections\n",
        "- **Support nested organization** for complex historical and cultural datasets\n",
        "\n",
        "**Functions for Scholarly Automation**\n",
        "- **Encapsulate analytical methods** so they can be applied systematically\n",
        "- **Ensure reproducible research** by codifying our scholarly procedures\n",
        "- **Handle repetitive tasks** efficiently across large cultural collections  \n",
        "- **Enable sophisticated analysis** that would be impossible to do manually\n",
        "- **Clean and standardize messy data** from historical and cultural sources\n",
        "\n",
        "**Professional Digital Humanities Skills**\n",
        "- **Data cleaning and standardization** for working with real-world cultural data\n",
        "- **Systematic analysis** of patterns across cultural collections\n",
        "- **Report generation** for sharing findings with scholarly communities\n",
        "- **Scalable research methods** that grow with the size of digital collections\n",
        "\n",
        "**Critical Digital Humanities Perspectives**\n",
        "- **Questioning our categories**: Understanding how our organizational choices shape our findings\n",
        "- **Balancing automation and interpretation**: Knowing when human judgment is essential\n",
        "- **Considering representation**: Being aware of whose voices and perspectives are included or excluded\n",
        "- **Thinking about access**: Understanding how technical barriers might limit scholarly participation\n",
        "\n",
        "These tools prepare you for advanced work in DH, from analyzing historical archives to studying contemporary digital culture. Remember, the technical skills are powerful, but the critical thinking about how we use them is what makes the work truly scholarly.\n",
        "\n",
        "As you continue your studies, you'll use these concepts to structure complex research data, automate analytical workflows, and ask new kinds of questions about culture and society. The combination of rich data organization and systematic analysis opens up entirely new possibilities for humanities scholarship."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}